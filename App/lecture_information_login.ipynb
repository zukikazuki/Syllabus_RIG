{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# セッションを開始\n",
    "session = requests.Session()\n",
    "\n",
    "# ログインページのURL\n",
    "login_url = \"https://syllabus.sfc.keio.ac.jp/users/sign_in?locale=ja&return_to=%2Fcourses%3Fbutton%3D%26locale%3Dja%26page%3D3%26search%255Bday_codes%255D%255B%255D%3D2%26search%255Bdepartments%255D%255B%255D%3D23%26search%255Bsemester%255D%3Dfall%26search%255Bsfc_guide_title%255D%3D%26search%255Bsub_semester%255D%3D%26search%255Bsummary%255D%3D%26search%255Bteacher_name%255D%3D%26search%255Btime_codes%255D%255B%255D%3D2%26search%255Btime_codes%255D%255B%255D%3D3%26search%255Btitle%255D%3D%26search%255Byear%255D%3D2024\"\n",
    "\n",
    "# ログインに必要なデータ (ユーザー名とパスワード)\n",
    "login_payload = {\n",
    "    'user[cns_account]': '',\n",
    "    'user[password]': ''\n",
    "}\n",
    "\n",
    "# ログインリクエストを送信\n",
    "response = session.post(login_url, data=login_payload)\n",
    "\n",
    "# ログイン成功したかどうかを確認\n",
    "if response.ok:\n",
    "    print(\"Login successful!\")\n",
    "else:\n",
    "    print(\"Login failed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 授業リンクを格納するリスト\n",
    "course_links_list = []\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# ページ番号を指定してスクレイピングを繰り返す\n",
    "for page in range(1, 28): \n",
    "    syllabus_url = f\"https://syllabus.sfc.keio.ac.jp/courses?button=&locale=ja&page={page}&search%5Bcommunication_type%5D%5B%5D=on_campus&search%5Bdepartments%5D%5B%5D=23&search%5Bobjective%5D=&search%5Bsemester%5D=fall&search%5Bsfc_guide_title%5D=&search%5Bsub_semester%5D=&search%5Bsummary%5D=&search%5Bteacher_name%5D=&search%5Btitle%5D=&search%5Byear%5D=2024\"\n",
    "    \n",
    "    syllabus_page = session.get(syllabus_url)\n",
    "    \n",
    "    soup = BeautifulSoup(syllabus_page.content, 'html.parser')\n",
    "    div_elements = soup.find_all('div', class_='detail-btn-wrapper')\n",
    "    for div in div_elements:\n",
    "        a_element = div.find('a', class_='detail-btn')\n",
    "        course_url = \"https://syllabus.sfc.keio.ac.jp\" + a_element['href']\n",
    "        course_links_list.append(course_url)\n",
    "        time.sleep(1)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(course_links_list, columns=[\"Course Link\"])\n",
    "df.to_csv('course_links_taimen.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対面授業以外\n",
    "# 授業リンクを格納するリスト\n",
    "course_links_list = []\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# ページ番号を指定してスクレイピングを繰り返す\n",
    "for page in range(1, 3):  # ページ数の範囲を適宜調整\n",
    "    syllabus_url = f\"https://syllabus.sfc.keio.ac.jp/courses?button=&locale=ja&page={page}&search%5Bcommunication_type%5D%5B%5D=online_live&search%5Bcommunication_type%5D%5B%5D=online_ondemand&search%5Bdepartments%5D%5B%5D=23&search%5Bobjective%5D=&search%5Bsemester%5D=fall&search%5Bsfc_guide_title%5D=&search%5Bsub_semester%5D=&search%5Bsummary%5D=&search%5Bteacher_name%5D=&search%5Btitle%5D=&search%5Byear%5D=2024\"\n",
    "    \n",
    "    # 各ページにリクエストを送信\n",
    "    syllabus_page = session.get(syllabus_url)\n",
    "    \n",
    "    # BeautifulSoupでHTMLをパース\n",
    "    soup = BeautifulSoup(syllabus_page.content, 'html.parser')\n",
    "    div_elements = soup.find_all('div', class_='detail-btn-wrapper')\n",
    "    for div in div_elements:\n",
    "        a_element = div.find('a', class_='detail-btn')\n",
    "        course_url = \"https://syllabus.sfc.keio.ac.jp\" + a_element['href']\n",
    "        course_links_list.append(course_url)\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(course_links_list, columns=[\"Course Link\"])\n",
    "df.to_csv('course_links_taimenigai.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv('course_links_taimen.csv')\n",
    "csv_2 = pd.read_csv('course_links_taimenigai.csv')\n",
    "csv_3 = pd.concat([csv_1, csv_2])\n",
    "csv_3.to_csv('course_links.csv', index=False, encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://syllabus.sfc.keio.ac.jp/courses/2024_45038?locale=ja'\n",
    "course_page = session.get(url)\n",
    "soup = BeautifulSoup(course_page.content, 'html.parser')\n",
    "soup_html = soup.prettify()\n",
    "with open('soup.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(soup_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrameの初期化 \n",
    "df_course_info = pd.DataFrame(columns=[\n",
    "    '学部・研究科', '登録番号', '科目ソート', '科目名', '分野', '単位', '開講年度・学期', 'K-Number', \n",
    "    '同一科目', 'アスペクト', '研究会テーマ', '曜日・時限', '授業教員名', '実施形態', '授業で使う言語', '授業で英語サポート', \n",
    "    '履修条件', 'その他推奨知識', '開講場所', '授業形態', '履修制限', \n",
    "    '受け入れ予定人数', '課題提出タイプ', '学生が利用する予定機材/ソフト等', \n",
    "    '履修上の注意・留意事項', '参考文献', '連絡先メールアドレス', 'GIGAサティフィケート対象', \n",
    "    '講義概要', '主題と目標', '提出課題・試験・成績評価の方法など', '第1回', '第2回' , '第3回', '第4回', '第5回', '第6回', '第7回', '第8回', '第9回', '第10回', '第11回', '第12回', '第13回', '第14回', '第15回',\n",
    "    'その他'\n",
    "])\n",
    "\n",
    "def get_course_info_from_url(course_url):\n",
    "    # URLからページを取得\n",
    "    response = session.get(course_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    dynamic_fields = dict.fromkeys(df_course_info.columns, '')\n",
    "    \n",
    "    # 科目名の取得\n",
    "    h2 = soup.find('h2')\n",
    "    course_name_span = h2.find('span', class_='title')\n",
    "    if course_name_span:\n",
    "        course_name = course_name_span.get_text(strip=True)\n",
    "        dynamic_fields['科目名'] = course_name\n",
    "\n",
    "    # 各セクションを解析\n",
    "    contents_boxes = soup.find_all('div', class_='contents-box')\n",
    "    for box in contents_boxes:\n",
    "        h3 = box.find('h3')\n",
    "        if h3:\n",
    "            section_title = h3.get_text(strip=True)\n",
    "            if section_title == '授業概要':\n",
    "                parse_jugyo_gaiyo(box, dynamic_fields)\n",
    "            elif section_title == '詳細':\n",
    "                parse_shosai(box, dynamic_fields)\n",
    "            elif section_title == '授業計画':\n",
    "                parse_jugyo_keikaku(box, dynamic_fields)\n",
    "    \n",
    "    df_course_info.loc[len(df_course_info)] = [dynamic_fields[col] for col in df_course_info.columns]\n",
    "\n",
    "def parse_jugyo_gaiyo(box, dynamic_fields):\n",
    "    # '授業概要'セクション\n",
    "    # 'class-info'と'syllabus-info'を解析\n",
    "    class_info = box.find('div', class_='class-info')\n",
    "    if class_info:\n",
    "        subject = class_info.find('div', class_='subject')\n",
    "        if subject:\n",
    "            dl_rows = subject.find_all('dl', class_='row')\n",
    "            for dl in dl_rows:\n",
    "                dts = dl.find_all('dt')\n",
    "                dds = dl.find_all('dd')\n",
    "                for dt, dd in zip(dts, dds):\n",
    "                    dt_text = dt.get_text(strip=True)\n",
    "                    dd_text = dd.get_text(strip=True)\n",
    "                    # DataFrameのカラム名と一致するか確認\n",
    "                    colomns = df_course_info.drop(columns=['科目名'])\n",
    "                    if dt_text in colomns.columns:\n",
    "                        dynamic_fields[dt_text] = dd_text\n",
    "    syllabus_info = box.find('div', class_='syllabus-info')\n",
    "    if syllabus_info:\n",
    "        dl_rows = syllabus_info.find_all('dl', class_='row')\n",
    "        for dl in dl_rows:\n",
    "            dt = dl.find('dt')\n",
    "            dd = dl.find('dd')\n",
    "            if dt and dd:\n",
    "                dt_text = dt.get_text(strip=True)\n",
    "                dd_text = dd.get_text(strip=True)\n",
    "                if dt_text in colomns.columns:\n",
    "                    dynamic_fields[dt_text] = dd_text\n",
    "\n",
    "def parse_shosai(box, dynamic_fields):\n",
    "    # '詳細'セクション\n",
    "    detail_info = box.find('dl', class_='detail-info')\n",
    "    if detail_info:\n",
    "        dts = detail_info.find_all('dt')\n",
    "        dds = detail_info.find_all('dd')\n",
    "        for dt, dd in zip(dts, dds):\n",
    "            dt_text = dt.get_text(strip=True)\n",
    "            dd_text = dd.get_text(strip=True)\n",
    "            if dt_text in df_course_info.columns:\n",
    "                dynamic_fields[dt_text] = dd_text\n",
    "\n",
    "def parse_jugyo_keikaku(box, dynamic_fields):\n",
    "    # '授業計画'セクション\n",
    "    lecture_info = box.find('dl', class_='lecture-info')\n",
    "    if lecture_info:\n",
    "        dts = lecture_info.find_all('dt')\n",
    "        dds = lecture_info.find_all('dd')\n",
    "        for dt, dd in zip(dts, dds):\n",
    "            # 講義タイトルの取得\n",
    "            title_span = dt.find('span', class_='title')\n",
    "            if title_span:\n",
    "                lecture_title = title_span.get_text(strip=True)\n",
    "                # '第X回'を抽出\n",
    "                if lecture_title.startswith('第'):\n",
    "                    lecture_number = lecture_title.split(' ')[0]\n",
    "                    if lecture_number in df_course_info.columns:\n",
    "                        dd_text = dd.get_text(strip=True)\n",
    "                        dynamic_fields[lecture_number] = lecture_title + '\\n' + dd_text\n",
    "                elif lecture_title == 'その他':\n",
    "                    if 'その他' in df_course_info.columns:\n",
    "                        dd_text = dd.get_text(strip=True)\n",
    "                        dynamic_fields['その他'] = dd_text\n",
    "\n",
    "# 出力制限を変更\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# CSVファイルを読み込む\n",
    "course_links = pd.read_csv('course_links.csv')['Course Link']\n",
    "\n",
    "for course_link in course_links:  # 10件だけ取得\n",
    "    get_course_info_from_url(course_link)\n",
    "    \n",
    "df_course_info.to_csv('course_info.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      https://syllabus.sfc.keio.ac.jp/courses/2024_39423?locale=ja\n",
      "1      https://syllabus.sfc.keio.ac.jp/courses/2024_48801?locale=ja\n",
      "2      https://syllabus.sfc.keio.ac.jp/courses/2024_48790?locale=ja\n",
      "3      https://syllabus.sfc.keio.ac.jp/courses/2024_48787?locale=ja\n",
      "4      https://syllabus.sfc.keio.ac.jp/courses/2024_48525?locale=ja\n",
      "                                   ...                             \n",
      "684    https://syllabus.sfc.keio.ac.jp/courses/2024_25954?locale=ja\n",
      "685    https://syllabus.sfc.keio.ac.jp/courses/2024_25956?locale=ja\n",
      "686    https://syllabus.sfc.keio.ac.jp/courses/2024_43756?locale=ja\n",
      "687    https://syllabus.sfc.keio.ac.jp/courses/2024_46238?locale=ja\n",
      "688    https://syllabus.sfc.keio.ac.jp/courses/2024_42656?locale=ja\n",
      "Name: Course Link, Length: 689, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 出力制限を変更\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# CSVファイルを読み込む\n",
    "course_links = pd.read_csv('course_links.csv')['Course Link']\n",
    "\n",
    "# 試験的に10件の授業情報を取得\n",
    "for course_link in course_links[:10]:\n",
    "    get_course_info_from_url(course_link)\n",
    "    \n",
    "df_course_info.to_csv('course_info.csv', index=False, encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt1: 学部・研究科\n",
      "dd1: 総合政策・環境情報学部\n",
      "dt2: 登録番号\n",
      "dd2: 00314\n",
      "dt3: 科目ソート\n",
      "dd3: A1101\n",
      "dt4: 科目名\n",
      "dd4: 研究会Ａ\n",
      "dt5: 分野\n",
      "dd5: 研究プロジェクト科目\n",
      "dt6: 単位\n",
      "dd6: 4単位\n",
      "dt7: 開講年度・学期\n",
      "dd7: 2024 秋学期\n",
      "dt8: K-Number\n",
      "dd8: FPE-CO-05003-211-88\n",
      "dt9: 研究会テーマ\n",
      "dd9: １）ことばとメディア、メディア（報道・広告・文学・映画・演劇・その他の舞台芸術）を対象に、「ことば」をデータとして分析し、考察する。２）外国語教育をデザインする（ツールや教材の作成・運用・評価など）＊いずれも、個人研究あるいは共同研究で実施\n",
      "dt10: 開講年度・学期\n",
      "dd10: 2024 秋学期\n",
      "dt11: 曜日・時限\n",
      "dd11: 月 4限    , 月 5限\n",
      "dt12: 授業教員名\n",
      "dd12: 藁谷　郁美\n",
      "dt13: 実施形態\n",
      "dd13: 対面\n",
      "dt14: 授業で使う言語\n",
      "dd14: 日本語\n",
      "dt15: 開講場所\n",
      "dd15: SFC, その他\n",
      "dt16: 授業形態※「授業形態」と「能動的学修形式」の対応についてはこちらをご覧ください。\n",
      "dd16: 講義, 演習, グループワーク\n",
      "dt17: GIGAサティフィケート対象\n",
      "dd17: 非対象\n",
      "dt18: 研究会・来期の研究プロジェクトのテーマ予定\n",
      "dd18: \n",
      "dt19: 講義概要\n",
      "dd19: この研究会では「ことばとメディア」を扱います。具体的にはふたつのプロジェクトから成り立ちます。(1)メディア比較研究プロジェクトおよび　(2) 学習環境構築プロジェクトです。それぞれ、個人研究レベルのテーマにより所属するプロジェクトを決めていただきますが、変更は学期途中でも可能です。授業内では基礎的作業部分は共有し、個人研究についてはグループワークを基盤に進めていきます。なお、研究会でのグループ活動では、各自、母語以外の言語を資料として扱うことを前提とします。　以下に、各プロジェクトの内容を記します。(1)メディア比較研究プロジェクト我々が日々接する報道や出来事に関連する情報は、さまざまなメディアのなかで「ことば」や「画像」「動画」によって提示される。COVID-19、大気汚染、地球温暖化、エネルギー転換など、日本だけでなくグローバルに共有するコンテンツが報じられている。これらのニュースコンテンツは、共通のテーマであっても、まったく異なる視点から提示される。日本語で発信されたニュースコンテンツに関して、英語、ドイツ語、フランス語、中国語、韓国語など、その発信「言語」が異なると、伝えられる内容も異なってくる。メディア言語の違いは、掲載される写真、選択される表現、重点領域、問題点の提示等の違いにもつながる。いったいどこに、その「違い」の要因があるのか。メディア表現の違いは、何を意味するのか。この研究会では、その問いを問題提起としながら、そこから問題発見・考察をじぶんで導くトレーニングをおこなう。様々な分野(文化、社会、教育、文学、宗教、芸術、フェミニズム、スポーツ等)を対象に、各自の問題意識に基づいてテーマを設定し、資料収集から考察・検討を行う。これまでの個人研究テーマには、3.11新聞記事の独英米比較分析、日本アニメーションの海外における受容とその分析、ミュージカル作品上演に伴う日欧比較、政治演説におけるノンバーバルコミュニケーション機能の日米比較、服飾デザイン広告をめぐる日米比較分析、スポーツ記事掲載における日英の視点の相違、翻訳を通した文学作品の受容と分析など多岐に亘る。(2) 学習環境構築　Learning Design Project (LDP)我々を取り巻く学習環境の変化は、COVID-19の影響以来、紙媒体が主流であった時代を背に、デジタル媒体、Web上での学習へと移行してきた。多様な媒体による、多様な学習の在り方を、各学習者が自分の学習スタイルに沿ってデザインしていく、この視点こそが重要である。「学習環境をどうデザインするのか」を問いながら、さまざまな実践・制作・運用をおこなう。本プロジェクトでは、１）学習スタイルの調査研究、２）教材作成と運用、３）学習教材の評価研究を柱に進めていく。個人研究テーマは外国語学習、デザイン、環境、歴史、文化等、各自が設定する。本研究会プロジェクトで作成された作品は、独英データベースを用いた語彙検索プログラム、動画データを用いたドイツ語学習教材、音声と顔の筋肉の動きをWebやiPhone上で同時に再生できる発音練習プログラム、中等教育を対象とした歴史シミュレーションゲーム、Web算数学習プログラム、初等教育を対象とした子供のための法律教本、生涯教育も視野に入れた学習としての茶道とそのデジタル教材作成など、多岐に亘る。シラバスを更に閲覧するにはCNSアカウントでログインが必要です\n"
     ]
    }
   ],
   "source": [
    "def get_course_html_from_url(course_url):\n",
    "    # URLからページを取得\n",
    "    response = session.get(course_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # dt と dd を取得してペアにする\n",
    "    dt_elements = soup.find_all('dt')\n",
    "    dd_elements = soup.find_all('dd')\n",
    "\n",
    "    n = 1\n",
    "    for dt, dd in zip(dt_elements, dd_elements):\n",
    "        dt_text = dt.get_text(strip=True)\n",
    "        dd_text = dd.get_text(strip=True)\n",
    "        print(f'dt{n}: {dt_text}')\n",
    "        print(f'dd{n}: {dd_text}')\n",
    "        n += 1\n",
    "\n",
    "get_course_html_from_url('https://syllabus.sfc.keio.ac.jp/courses/2024_39423?locale=ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://syllabus.sfc.keio.ac.jp/courses/2024_35765?locale=ja'\n",
    "\n",
    "df_course_info = pd.DataFrame(columns=[\n",
    "    '学部・研究科', '登録番号', '科目ソート', '科目名', '分野', '単位', '開講年度・学期', 'K-Number', \n",
    "    '同一科目', 'アスペクト', '研究会テーマ', '曜日・時限', '授業教員名', '実施形態', '授業で使う言語', '授業で英語サポート', \n",
    "    '履修条件', 'その他推奨知識', '開講場所', '授業形態', '履修制限', \n",
    "    '受け入れ予定人数', '課題提出タイプ', '学生が利用する予定機材/ソフト等', \n",
    "    '履修上の注意・留意事項', '参考文献', '連絡先メールアドレス', 'GIGAサティフィケート対象', \n",
    "    '講義概要', '主題と目標', '提出課題・試験・成績評価の方法など', '第1回', '第2回' , '第3回', '第4回', '第5回', '第6回', '第7回', '第8回', '第9回', '第10回', '第11回', '第12回', '第13回', '第14回', '第15回',\n",
    "    'その他'\n",
    "])\n",
    "\n",
    "def get_course_html_from_url_test(course_url):\n",
    "    # URLからページを取得\n",
    "    response = session.get(course_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    h2 = soup.find('h2')\n",
    "    if h2:\n",
    "        course_name_span = h2.find('span', class_='title')\n",
    "        if course_name_span:\n",
    "            course_name = course_name_span.get_text(strip=True)\n",
    "            print(f'科目名: {course_name}')\n",
    "\n",
    "get_course_info_from_url(url)\n",
    "df_course_info.to_csv('course_info_test.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syllabus_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
